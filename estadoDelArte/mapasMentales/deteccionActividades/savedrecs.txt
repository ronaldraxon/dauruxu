PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	RP	EM	RI	OI	FU	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	D2	EA	PG	WC	SC	GA	UT	PM	OA	HC	HP	DA
J	Yahaya, SW; Lotfi, A; Mahmud, M				Yahaya, Salisu Wada; Lotfi, Ahmad; Mahmud, Mufti			A Consensus Novelty Detection Ensemble Approach for Anomaly Detection in Activities of Daily Living	APPLIED SOFT COMPUTING			English	Article						Novelty Detection; Outlier detection; Internal consensus; External consensus; Abnormality detection; Activities of Daily Living (ADL); Normality score; Normality threshold; Weight estimation	ABNORMAL-BEHAVIOR; CLASSIFICATION; RECOGNITION	A new approach to creating an ensemble of novelty detection algorithms is proposed in this paper. The novelty detection process identifies new or unknown data by detecting if a test data differs significantly from the data available during training. It is applicable for anomaly detection in a situation where there is sufficiently large training data representing the normal class and little or no training data for the anomalous (abnormal) class. Abnormality in Activities of Daily Living (ADL) is identified as any significant deviation from an individual's usual behavioural routine. Novelty detection is relevant to ADL anomaly detection since abnormalities in ADL are rare and data representing the anomalous cases are not readily available. The proposed Consensus Novelty Detection Ensemble approach is based on the concept of internal and external consensus. The internal consensus is an internal voting scheme within each model in the ensemble while the external consensus is an external voting scheme among the ensemble models. The weight of each model is estimated based on its performance and a score, called "Normality Score''. Computed score is used in classifying the data as abnormal (anomalous) based on certain threshold crossing, normal otherwise. Experimental evaluation is conducted to detect abnormalities in ADL data obtained from CASAS repository as well as experimental dataset collected for this research. The obtained results show that the proposed approach is able to identify anomalous instances. The proposed approach offers more flexibility compared with the existing approaches by allowing the Normality Score threshold to be adjusted without retraining the models. (C) 2019 Elsevier B.V. All rights reserved.	[Yahaya, Salisu Wada; Lotfi, Ahmad; Mahmud, Mufti] Nottingham Trent Univ, Sch Sci & Technol, Nottingham NG11 8NS, England	Lotfi, A (reprint author), Nottingham Trent Univ, Sch Sci & Technol, Nottingham NG11 8NS, England.	salisu.yahaya2015@ntu.ac.uk; ahmad.lotfi@ntu.ac.uk; mufti.mahmud@ntu.ac.uk	; Lotfi, Ahmad/D-4260-2009	Yahaya, Salisu/0000-0002-0394-6112; Mahmud, Mufti/0000-0002-2037-8348; Lotfi, Ahmad/0000-0002-5139-6565	Nottingham Trent University (United Kingdom) through Vice Chancellor Studentship Scheme	This research project is supported by Nottingham Trent University (United Kingdom) through Vice Chancellor Studentship Scheme provided to Salisu Wada Yahaya.	Alberdi A, 2018, IEEE J BIOMED HEALTH, V22, P1720, DOI 10.1109/JBHI.2018.2798062; Aramendi AA, 2018, J BIOMED INFORM, V81, P119, DOI 10.1016/j.jbi.2018.03.009; Ali I, 2011, ANNU IEEE IND CONF; Arifoglu D, 2019, ARTIF INTELL MED, V94, P88, DOI 10.1016/j.artmed.2019.01.005; Arifoglu D, 2017, PROCEDIA COMPUT SCI, V110, P86, DOI 10.1016/j.procs.2017.06.121; Borazio M, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI), P125, DOI 10.1109/ICHI.2014.24; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953; Chernbumroong S, 2013, EXPERT SYST APPL, V40, P1662, DOI 10.1016/j.eswa.2012.09.004; Cook DJ, 2014, J INTELL INF SYST, V43, P503, DOI 10.1007/s10844-014-0341-4; Cook DJ, 2013, COMPUTER, V46, P62, DOI 10.1109/MC.2012.328; Dai XX, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (ICIA), P1, DOI 10.1109/ICInfA.2016.7831788; Dawadi PN, 2016, IEEE J BIOMED HEALTH, V20, P1188, DOI 10.1109/JBHI.2015.2445754; Dib G, 2018, SMART MATER STRUCT, V27, DOI 10.1088/1361-665X/aa973f; Dreiseitl S., 2010, P AMIA ANN FALL S; Fahad LG, 2015, 2015 IEEE 14TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P419, DOI 10.1109/ICMLA.2015.195; Forkan ARM, 2015, PATTERN RECOGN, V48, P628, DOI 10.1016/j.patcog.2014.07.007; Gardner A., 2006, J MACH LEARN RES; Haigh KZ, 2006, ASSIST TECHNOL, V18, P87, DOI 10.1080/10400435.2006.10131909; Hoque E, 2015, 2015 INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING IN SENSOR SYSTEMS (DCOSS), P40, DOI 10.1109/DCOSS.2015.20; Jakkula Vikramaditya, 2007, 3rd IET International Conference on Intelligent Environments, IE 07, P339; Jakkula V., 2011, P 7 AAAI C ART INT S, P33; James G., 2014, INTRO STAT LEARNING; Khan SS, 2014, KNOWL ENG REV, V29, P345, DOI 10.1017/S026988891300043X; Liu FT, 2008, IEEE DATA MINING, P413, DOI 10.1109/ICDM.2008.17; Lotfi A, 2012, J AMB INTEL HUM COMP, V3, P205, DOI 10.1007/s12652-010-0043-x; Ma J., 2003, P INT JOINT C NEUR N; Mahmud M, 2018, COGN COMPUT, V10, P864, DOI 10.1007/s12559-018-9543-3; Nairac A, 1997, IEE CONF PUBL, P117, DOI 10.1049/cp:19970712; Ni Q, 2015, SENSORS-BASEL, V15, P11312, DOI 10.3390/s150511312; Novak M., 2012, 2012 Proceedings of the 9th Conference of ELEKTRO (ELEKTRO 2012), P341, DOI 10.1109/ELEKTRO.2012.6225617; Novak M., 2013, J SEL AREAS HLTH INF, V3, P1; Pasillas-Diaz JR, 2016, ELECTRON NOTES THEOR, V329, P61, DOI 10.1016/j.entcs.2016.12.005; Pimentel MAF, 2014, SIGNAL PROCESS, V99, P215, DOI 10.1016/j.sigpro.2013.12.026; Rashidi P, 2013, IEEE J BIOMED HEALTH, V17, P579, DOI 10.1109/JBHI.2012.2234129; Syed Z., 2010, AMIA ANN S P; Tarassenko L., 1995, Fourth International Conference on `Artificial Neural Networks' (Conf. Publ. No.409), P442, DOI 10.1049/cp:19950597; Theissler A., 2017, 2017 IEEE 15 INT C I, P750; Yahaya SW, 2019, ADV INTELL SYST, V840, P362, DOI 10.1007/978-3-319-97982-3_30; Yeung DY, 2002, INT C PATT RECOG, P385, DOI 10.1109/ICPR.2002.1047476	39	1	1	4	4	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	1568-4946	1872-9681		APPL SOFT COMPUT	Appl. Soft. Comput.	OCT	2019	83								UNSP 105613	10.1016/j.asoc.2019.105613			13	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Computer Science	JA8KN	WOS:000488100900014					2020-03-04	
J	Wang, BY; Hoai, M				Wang, Boyu; Minh Hoai			Back to the beginning: Starting point detection for early recognition of ongoing human actions	COMPUTER VISION AND IMAGE UNDERSTANDING			English	Article						Action early recognition; Online action detection; Event detection		We address the task of recognizing the category of an ongoing human action from a video stream. This task is challenging because of the need to output categorization decisions based on partial evidence-the action has not finished and not all information about the action has been observed. This task is further complicated because the ongoing action is submerged in the stream of data and the start of the action is not given. Existing methods for early recognition usually ignore this issue, making unrealistic assumption about the availability of the starting point of the ongoing action. In this paper, we prove the importance of starting point detection and subsequently propose a method to determine the start of an ongoing action. Our method is based on a bidirectional recurrent neural network that computes the probability of a frame to be the starting point by comparing the dynamics of the actions before and after the frame. Experiments on three datasets show that our method can reliably detect the starting point of an ongoing action, improving the early recognition accuracy.	[Wang, Boyu; Minh Hoai] SUNY Stony Brook, Stony Brook, NY 11794 USA	Wang, BY (reprint author), SUNY Stony Brook, Stony Brook, NY 11794 USA.	boywang@cs.stonybrook.edu			National Science Foundation, United States Award [IIS-1566248]; Brookhaven National Lab, United States	This project is partially supported by the National Science Foundation, United States Award IIS-1566248 and Brookhaven National Lab, United States.	Basseville M., 1993, DETECTION ABRUPT CHA, V104; Berkes L., 2004, SEQUENTIAL CHANGE PO, V20, P1140; Cao Y., 2013, P CVPR; Dave A., 2017, ARXIV170403615; Donahue J., 2015, P CVPR; Ellis C, 2013, INT J COMPUT VISION, V101, P420, DOI 10.1007/s11263-012-0550-7; Enikeeva F., 2013, ARXIV13121900; Escalera S., 2014, P ECCV WORKSH; Fawcett T., 1999, P KDD; Graves A, 2005, ARTIFICIAL NEURAL NE; Heilbron F. C., 2015, P CVPR; Hoai M., 2012, ARTIFICIAL INTELLIGE; Hoai M., 2011, P CVPR; Hoai M, 2014, PATTERN RECOGN, V47, P1523, DOI 10.1016/j.patcog.2013.09.028; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735; Hu J., 2016, P ECCV; Huang D., 2014, P ECCV; Kiran BR, 2018, J IMAGING, V4, DOI 10.3390/jimaging4020036; Kitani K. M., 2012, P ECCV; Kong Y., 2014, P ECCV; Lan T., 2014, P ECCV; Lan T., 2011, P ICCV; Lee Honglak, 2006, NIPS; Li Y., 2016, P ECCV; Luo J., 2013, P ICCV; Ma S., 2016, P CVPR; Malhotra Pankaj, 2015, LONG SHORT TERM MEMO, P89; Marchi E., 2015, ICASSP; Hoai M, 2014, INT J COMPUT VISION, V107, P191, DOI 10.1007/s11263-013-0683-3; Ng Joe Yue-Hei, 2015, P CVPR; Nguyen M. H., 2009, P ICCV; Ni B., 2014, P CVPR; Oliver N, 2004, COMPUT VIS IMAGE UND, V96, P163, DOI 10.1016/j.cviu.2004.02.004; PICARD D, 1985, ADV APPL PROBAB, V17, P841, DOI 10.2307/1427090; Poor H. V., 2009, QUICKEST DETECTION, V40; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Raptis M., 2013, P CVPR; Rohrbach M., 2015, P ICCV; Rumelhart D.E., 1986, PARALLEL DISTRIBUTED, V1, P318, DOI DOI 10.1016/B978-1-4832-1446-7.50035-2; Ryoo M., 2011, P ICCV; Ryoo M., 2009, P ICCV; Ryoo M. S., 2015, INT C HUM ROB INT; Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093; Shou  Z., 2018, EUR C COMP VIS ECCV; Simonyan K., 2014, NIPS; Singh G., 2017, P ICCV; Soomro K, 2016, ARXIV161201194; Tian Y., 2013, P CVPR; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Vapnik V.N., 1998, STAT LEARNING THEORY; Veeriah V., 2015, P ICCV; Vondrick C., 2016, P CVPR; Wang B., 2018, PREDICTING BODY MOVE; Wang L., 2016, P ECCV; Wang Y., 2016, IMPROVING HUMAN ACTI; Wang Y., 2018, PULLING ACTIONS OUT; Wei Z., 2018, SEQUENCE TO SEGMENT; Weston J., 2014, ARXIV14103916; Xia L., 2012, P CVPR WORKSH; Xie Y, 2013, IEEE J-STSP, V7, P12, DOI 10.1109/JSTSP.2012.2234082; Xu Z., 2015, P ICCV; Yacoob Y, 1999, COMPUT VIS IMAGE UND, V73, P232, DOI 10.1006/cviu.1998.0726; Yang J. C., 2009, P CVPR; Yu G., 2015, P CVPR; Yu G., 2015, P ACCV; Yuan J., 2009, P CVPR; Zanfir M., 2013, P ICCV	67	0	0	1	5	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1077-3142	1090-235X		COMPUT VIS IMAGE UND	Comput. Vis. Image Underst.	OCT	2018	175						24	31		10.1016/j.cviu.2018.09.001			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	HF4EA	WOS:000454184800003					2020-03-04	
J	Lin, C; Xu, GL; Cao, YJ				Lin, Chuan; Xu, Guili; Cao, Yijun			Contour detection model based on neuron behaviour in primary visual cortex	IET COMPUTER VISION			English	Article						eye; neurophysiology; visual evoked potentials; biomechanics; edge detection; image texture; image filtering; medical image processing; contour detection model; neuron behaviour; mammalian primary visual cortex; classical receptive field; CRF; visual stimuli; nonCRF neuron inhibition; saturation properties; neuron response; fixational eye movements; FEyeMs; threshold method; multichannel filter bank; object contour preservation; isolated texture inhibition	NONCLASSICAL RECEPTIVE-FIELD; FIXATIONAL EYE-MOVEMENTS; SURROUND SUPPRESSION; STRIATE CORTEX; CONTEXTUAL INTERACTIONS; SPATIAL-FREQUENCY; INHIBITION; RESPONSES; MACAQUE; V1	In the mammalian primary visual cortex, the response of the classical receptive field (CRF) to visual stimuli can be suppressed by inhibition of non-CRF (nCRF) neurons. Although many biologically plausible models based on these centre-surround interaction properties have been proposed, most of these models have failed to account for two important behaviours of neurons in the primary visual cortex (V1). First, saturation properties of neuron response. Second, the properties of fixational eye movements (FEyeMs). In the present study, the authors proposed a biologically motivated counter detection approach based on these properties. The authors' work is significant in that they utilised a simple threshold method to ensure that CRF responses were observed within a meaningful range, and multichannel filter bank was proposed to simulate the influence of FEyeMs on nCRF. Both methods effectively preserved object contours and inhibition isolated textures. Extensive experiments indicated that the authors' model can preserve more object contours and suppress more textures than previous biologically based models.	[Lin, Chuan; Xu, Guili] Nanjing Univ Aeronaut & Astronaut, Coll Automat Engn, Yudao St 29, Nanjing, Jiangsu, Peoples R China; [Lin, Chuan; Cao, Yijun] Guangxi Univ Sci & Technol, Coll Elect & Informat Engn, Donghuan Rd 268, Liuzhou, Guangxi, Peoples R China	Xu, GL (reprint author), Nanjing Univ Aeronaut & Astronaut, Coll Automat Engn, Yudao St 29, Nanjing, Jiangsu, Peoples R China.	guilixu@nuaa.edu.cn			National Natural Science Foundation of ChinaNational Natural Science Foundation of China [61473148]; Guangxi Natural Science FoundationNational Natural Science Foundation of Guangxi Province [2015GXNSFAA139293]	The authors appreciate the anonymous reviewers for their helpful and constructive comments on an earlier draft of this paper. This work was supported by the National Natural Science Foundation of China (grant number 61473148) and Guangxi Natural Science Foundation (grant number 2015GXNSFAA139293). The funders had no role in the study design; in the collection, analysis, or interpretation of data; in the writing of the report; or in the decision to submit the article for publication.	Bair W, 1998, VISUAL NEUROSCI, V15, P779, DOI 10.1017/S0952523898154160; Bosman CA, 2009, J NEUROSCI, V29, P9471, DOI 10.1523/JNEUROSCI.1193-09.2009; Bredfeldt CE, 2002, J NEUROSCI, V22, P1976, DOI 10.1523/JNEUROSCI.22-05-01976.2002; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Carpenter R. H, 1988, MOVEMENTS EYES; CORNSWEET TN, 1956, J OPT SOC AM, V46, P987, DOI 10.1364/JOSA.46.000987; Das A, 1999, NATURE, V399, P655, DOI 10.1038/21371; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; DITCHBURN RW, 1953, J PHYSIOL-LONDON, V119, P1; DITCHBURN RW, 1980, VISION RES, V20, P271, DOI 10.1016/0042-6989(80)90112-1; Dragoi V, 2000, J NEUROPHYSIOL, V83, P1019; ENROTHCUGELL C, 1980, J PHYSIOL-LONDON, V302, P49; ERIKSEN CW, 1971, PERCEPT PSYCHOPHYS, V10, P321, DOI 10.3758/BF03207451; Ernst U., 2012, BMC NEUROSCI S1, V13, pO4; Gao S., 2014, EUR C COMP VIS ZUR S; Gao S., 2013, P IEEE INT C COMP VI; Gao SB, 2015, IEEE T PATTERN ANAL, V37, P1973, DOI 10.1109/TPAMI.2015.2396053; Gregoriou GG, 2009, SCIENCE, V324, P1207, DOI 10.1126/science.1171402; Greschner M, 2002, NAT NEUROSCI, V5, P341, DOI 10.1038/nn821; Grigorescu C, 2004, IMAGE VISION COMPUT, V22, P609, DOI 10.1016/j.imavis.2003.12.004; Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P729, DOI 10.1109/TIP.2003.814250; Hamm JP, 2010, J NEUROSCI, V30, P7350, DOI 10.1523/JNEUROSCI.0785-10.2010; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837; HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574, DOI 10.1113/jphysiol.1959.sp006308; Jones HE, 2001, J NEUROPHYSIOL, V86, P2011; JONES JP, 1987, J NEUROPHYSIOL, V58, P1233; Kandel ER, 2000, PRINCIPLES NEURAL SC; Kapadia MK, 2000, J NEUROPHYSIOL, V84, P2048; KAPADIA MK, 1995, NEURON, V15, P843, DOI 10.1016/0896-6273(95)90175-2; KNIERIM JJ, 1992, J NEUROPHYSIOL, V67, P961; Krauzlis R. J., 2008, FUNDAMENTAL NEUROSCI, P775; Leopold DA, 1998, EXP BRAIN RES, V123, P341, DOI 10.1007/s002210050577; Levitt JB, 1997, NATURE, V387, P73, DOI 10.1038/387073a0; Li CY, 1996, NEWS PHYSIOL SCI, V11, P181; LI CY, 1994, VISION RES, V34, P2337, DOI 10.1016/0042-6989(94)90280-1; Lin C, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.4.043018; Martin D., 2001, COMP VIS 2001 ICCV 2; Martinez-Conde S, 2002, P NATL ACAD SCI USA, V99, P13920, DOI 10.1073/pnas.212500599; Martinez-Conde S, 2000, NAT NEUROSCI, V3, P251, DOI 10.1038/72961; Olkkonen M, 2008, J VISION, V8, DOI [10.1167/8.5.13, 10.1167/8.8.8]; Papari G, 2011, PATTERN RECOGN, V44, P1999, DOI 10.1016/j.patcog.2010.08.013; Pereda AE, 2014, NAT REV NEUROSCI, V15, P250, DOI 10.1038/nrn3708; Petkov N, 2003, BIOL CYBERN, V88, P236, DOI 10.1007/s00422-002-0378-2; Polat U, 1998, NATURE, V391, P580, DOI 10.1038/35372; POSNER MI, 1980, Q J EXP PSYCHOL, V32, P3, DOI 10.1080/00335558008248231; RATLIFF F, 1950, J EXP PSYCHOL, V40, P687, DOI 10.1037/h0057754; RIGGS LA, 1953, J OPT SOC AM, V43, P495, DOI 10.1364/JOSA.43.000495; Rolfs M, 2009, VISION RES, V49, P2415, DOI 10.1016/j.visres.2009.08.010; Ross WD, 2000, NEURAL NETWORKS, V13, P571, DOI 10.1016/S0893-6080(00)00040-X; Snodderly DM, 2001, VISUAL NEUROSCI, V18, P259, DOI 10.1017/S0952523801182118; SOMERS DC, 1995, J NEUROSCI, V15, P5448; Spratling MW, 2013, IEEE T IMAGE PROCESS, V22, P1629, DOI 10.1109/TIP.2012.2235850; Tang QL, 2007, PATTERN RECOGN, V40, P3100, DOI 10.1016/j.patcog.2007.02.009; Ursino M, 2004, NEURAL NETWORKS, V17, P719, DOI 10.1016/j.neunet.2004.03.007; Walker GA, 2000, VISUAL NEUROSCI, V17, P369, DOI 10.1017/S0952523800173055; Wei H, 2013, NEUROCOMPUTING, V103, P247, DOI 10.1016/j.neucom.2012.09.027; WERBLIN FS, 1972, SCIENCE, V175, P1008, DOI 10.1126/science.175.4025.1008; Wright RD, 2008, ORIENTING ATTENTION; Xu WF, 2005, CEREB CORTEX, V15, P1697, DOI 10.1093/cercor/bhi046; Yang K., 2013, P IEEE C COMP VIS PA; Yang KF, 2015, FRONT NEURAL CIRCUIT, V9, DOI 10.3389/fncir.2015.00030; Yang KF, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2425538; Yang KF, 2012, COMM COM INF SC, V321, P145; Yarbus AL., 1967, EYE MOVEMENTS VISION, P171, DOI DOI 10.1007/978-1-4899-5379-7_8; Zeng C, 2011, NEUROCOMPUTING, V74, P1527, DOI 10.1016/j.neucom.2010.12.022; Zeng C, 2011, NEUROIMAGE, V55, P49, DOI 10.1016/j.neuroimage.2010.11.067; Zhang XS, 2016, IEEE T IMAGE PROCESS, V25, P1219, DOI 10.1109/TIP.2016.2516953	67	1	2	3	8	INST ENGINEERING TECHNOLOGY-IET	HERTFORD	MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND	1751-9632	1751-9640		IET COMPUT VIS	IET Comput. Vis.	SEP	2018	12	6					863	872		10.1049/iet-cvi.2017.0661			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Computer Science; Engineering	GQ1MT	WOS:000441397000012					2020-03-04	
