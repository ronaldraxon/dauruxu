print(hola)
print("hola")
install.packages(c("gridExtra", "reticulate"))
base_completa<-read.csv("../7_datasets/IMB579-XLS-ENG_Complete.csv",sep =",",header=TRUE)
dim(base_completa)
aggr_plot <- aggr(base_completa, col=c('navyblue','red'),
numbers=TRUE, sortVars=TRUE, labels=names(STCdata_A),
cex.axis=.7, gap=3,
ylab=c("Histograma de valores faltantes","Patrón"))
library(VIM)
aggr_plot <- aggr(base_completa, col=c('navyblue','red'),
numbers=TRUE, sortVars=TRUE, labels=names(STCdata_A),
cex.axis=.7, gap=3,
ylab=c("Histograma de valores faltantes","Patrón"))
library(VIM)
aggr_plot <- aggr(base_completa, col=c('navyblue','red'),
numbers=TRUE, sortVars=TRUE, labels=names(base_completa),
cex.axis=.7, gap=3,
ylab=c("Histograma de valores faltantes","Patrón"))
library(VIM)
aggr_plot <- aggr(base_completa, col=c('navyblue','red'),
numbers=TRUE, sortVars=TRUE, labels=names(base_completa),
cex.axis=.7, gap=3,
ylab=c("Histograma de valores faltantes","Patrón"))
library(VIM)
aggr_plot <- aggr(base_completa, col=c('navyblue','red'),
numbers=TRUE, sortVars=TRUE, labels=names(base_completa),
cex.axis=.7, gap=3,
ylab=c("Histograma de valores faltantes","Patrón"))
library(VIM)
aggr_plot <- aggr(base_completa, col=c('navyblue','red'),
numbers=TRUE, sortVars=TRUE, labels=names(base_completa),
cex.axis=.7, gap=3,
ylab=c("Histograma de valores faltantes","Patrón"))
str(base_completa,vec.len=2)
faltantes <- base_completa
faltantes$C.MANIPULATOR <- as.factor(faltantes$C.MANIPULATOR)
aggr_plot <- aggr(faltantes, col=c('navyblue','red'),
numbers=TRUE, sortVars=TRUE, labels=names(faltantes),
cex.axis=.7, gap=3,
ylab=c("Histograma de valores faltantes","Patrón"))
faltantes <- base_completa
faltantes$C.MANIPULATOR <- as.factor(faltantes$C.MANIPULATOR)
str(faltantes)
#aggr_plot <- aggr(faltantes, col=c('navyblue','red'),
#                  numbers=TRUE, sortVars=TRUE, labels=names(faltantes),
#                  cex.axis=.7, gap=3,
#                  ylab=c("Histograma de valores faltantes","Patrón"))
boxplot(DSRI, data=base_completa, notch=TRUE,
col=(c("gold","darkgreen")),
main="Distribución", xlab="Variable")
boxplot(base_completa$DSRI, data=base_completa, notch=TRUE,
col=(c("gold","darkgreen")),
main="Distribución", xlab="Variable")
boxplot(base_completa, data=base_completa, notch=TRUE,
col=(c("gold","darkgreen")),
main="Distribución", xlab="Variable")
boxplot(base_completa[-Company.ID], data=base_completa, notch=TRUE,
col=(c("gold","darkgreen")),
main="Distribución", xlab="Variable")
extremos<- base_completa%>%
select(DSRI,GMI,AQI)
library(dplyr)
extremos<- base_completa %>%
select(DSRI,GMI,AQI)
boxplot(extremos, data=base_completa, notch=TRUE,
col=(c("gold","darkgreen")),
main="Distribución", xlab="Variable")
library(dplyr)
extremos<- base_completa %>%
select(DSRI,GMI,AQI)
boxplot(extremos, data=base_completa, notch=TRUE,
col=(c("gold","darkgreen")),
main="Distribución", xlab="Variable")
library(dplyr)
extremos<- base_completa %>%
select(DSRI,GMI,AQI,SGI)
boxplot(extremos, data=base_completa, notch=TRUE,
col=(c("gold","darkgreen")),
main="Distribución", xlab="Variable")
library(dplyr)
extremos<- base_completa %>%
select(DSRI,GMI,AQI,SGI)
boxplot(extremos, data=base_completa, notch=TRUE,
col=(c("gold","darkgreen")),
main="Distribución y atípicos de índices", xlab="Variables")
extremos<- base_completa %>%
select(DSRI,GMI,AQI,SGI)
boxplot(extremos, data=base_completa, notch=TRUE,
col=(c("gold","darkgreen")),
main="Distribución y atípicos de índices", xlab="Variables")
extremos<- base_completa %>%
select(DEPI,SGAI,ACCR,LEVI)
boxplot(extremos, data=base_completa, notch=TRUE,
col=(c("gold","darkgreen")),
main="Distribución y atípicos de índices", xlab="Variables")
extremos<- base_completa %>%
select(DEPI,SGAI,ACCR,LEVI)
boxplot(extremos, data=base_completa, notch=TRUE,
col=(c("gold","darkgreen")),
main="Distribución y atípicos de índices 2", xlab="Variables")
extremos<- base_completa %>%
select(DEPI,SGAI,ACCR,LEVI)
boxplot(extremos, data=base_completa, notch=TRUE,
col=(c("gold","darkgreen")),
main="Distribución y atípicos de índices 2")
extremos<- base_completa %>%
select(DEPI,SGAI,ACCR,LEVI)
boxplot(extremos, data=base_completa, notch=TRUE,
col=(c("gold","darkgreen")),
main="Distribución y atípicos de índices 2", xlab="Variables")
ggplot(base_completa, aes(x=weight)) +
geom_histogram(aes(y=..density..), colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666")
library(ggplot2)
ggplot(base_completa, aes(x=weight)) +
geom_histogram(aes(y=..density..), colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666")
library(ggplot2)
ggplot(base_completa, aes(x=DRSI)) +
geom_histogram(aes(y=..density..), colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666")
library(ggplot2)
ggplot(base_completa, aes(x=DSRI)) +
geom_histogram(aes(y=..density..), colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666")
library(ggplot2)
ggplot(base_completa, aes(x=DSRI,xintercept=mean(DSRI))) +
geom_histogram(aes(y=..density..), colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666")
library(ggplot2)
ggplot(base_completa, aes(x=DSRI)) +
geom_histogram(aes(y=..density..), colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666") +
geom_vline(aes(xintercept=mean(weight)),
color="blue", linetype="dashed", size=1)
library(ggplot2)
ggplot(base_completa, aes(x=DSRI)) +
geom_histogram(aes(y=..density..), colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666") +
geom_vline(aes(xintercept=mean(DSRI)),
color="blue", linetype="dashed", size=1)
library(ggplot2)
ggplot(base_completa, aes(x=DSRI)) +
geom_histogram(aes(y=..densidad..), colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666") +
geom_vline(aes(xintercept=mean(DSRI)),
color="blue", linetype="dashed", size=1)
library(ggplot2)
ggplot(base_completa, aes(x=DSRI)) +
geom_histogram(aes(y=..density..), colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666") +
geom_vline(aes(xintercept=mean(DSRI)),
color="blue", linetype="dashed", size=1)
library(ggplot2)
ggplot(base_completa, aes(x=DSRI)) +
geom_vline(aes(xintercept=mean(DSRI)),
color="blue", linetype="dashed", size=1)
library(ggplot2)
ggplot(base_completa, aes(x=DSRI)) +
geom_histogram(colour="black", fill="white")+
geom_density(alpha=.2, fill="#FF6666") +
geom_vline(aes(xintercept=mean(DSRI)),
color="blue", linetype="dashed", size=1)
library(ggplot2)
ggplot(base_completa, aes(x=DSRI)) +
geom_histogram(colour="black", fill="white")+
geom_vline(aes(xintercept=mean(DSRI)),
color="blue", linetype="dashed", size=1)
distribucion_DSRI <- ggplot(base_completa, aes(x=DSRI)) +
geom_histogram(colour="black", fill="white")+
geom_vline(aes(xintercept=mean(DSRI)),
color="blue", linetype="dashed", size=1)
incidencia_DSRI <- ggplot(base_completa, aes(x = Manipulater, y = DSRI))
ggplot(base_completa, aes(x = Manipulater, y = DSRI))
incidencia_DSRI <- ggplot(base_completa, aes(x = Manipulater, y = DSRI)) +
geom_point(color = Manipulater, size = 2, shape = 23)
incidencia_DSRI <- ggplot(base_completa, aes(x = Manipulater, y = DSRI)) +
geom_point(color = base_completa$Manipulater, size = 2, shape = 23)
ggplot(base_completa, aes(x = Manipulater, y = DSRI)) +
geom_point(color = base_completa$Manipulater, size = 2, shape = 23)
incidencia_DSRI <- ggplot(base_completa, aes(x = Manipulater, y = DSRI)) +
geom_point(color = base_completa$Manipulater, size = 2, shape = 23)
incidencia_DSRI <- ggplot(base_completa, aes(x = Manipulater, y = DSRI)) +
geom_point(aes(shape = 23, color = Manipulater))
ggplot(base_completa, aes(x = Manipulater, y = DSRI)) +
geom_point(aes(shape = 23, color = Manipulater))
ggplot(base_completa, aes(x = Manipulater, y = DSRI)) +
geom_point(aes(color = Manipulater))
install.packages("Hmisc")
library(e1071)
library(dplyr)
library(caret)
library(kableExtra)
#17
base_1_escal_u17_train<-read.csv2("../7_datasets/base_1_escal_us17_train.csv",sep =";",header=TRUE,dec=",")
base_1_escal_u17_test<-read.csv2("../7_datasets/base_1_escal_us17_test.csv",sep =";",header=TRUE,dec=",")
#Escalados
base_1_S_u17_train<- base_1_escal_u17_train%>%select(DSRI_S,GMI_S,AQI_S,SGI_S,DEPI_S,SGAI_S,ACCR_S,LEVI_S,C.MANIPULATOR)
base_1_S_u17_train$C.MANIPULATOR<-as.factor(base_1_escal_u17_train$C.MANIPULATOR)
base_1_S_u17_test<- base_1_escal_u17_test%>%select(DSRI_S,GMI_S,AQI_S,SGI_S,DEPI_S,SGAI_S,ACCR_S,LEVI_S,C.MANIPULATOR)
base_1_S_u17_test$C.MANIPULATOR <- as.factor(base_1_escal_u17_test$C.MANIPULATOR)
#SMOTE
base_1_escal_SMOTE_train<-read.csv2("../7_datasets/base_1_escal_SMOTE_train.csv",sep =";",header=TRUE,dec=",")
base_1_escal_SMOTE_test<-read.csv2("../7_datasets/base_1_escal_SMOTE_test.csv",sep =";",header=TRUE,dec=",")
#Escalados
base_1_S_SMOTE_train<- base_1_escal_SMOTE_train%>%select(DSRI_S,GMI_S,AQI_S,SGI_S,DEPI_S,SGAI_S,ACCR_S,LEVI_S,C.MANIPULATOR)
base_1_S_SMOTE_train$C.MANIPULATOR<-as.factor(base_1_escal_SMOTE_train$C.MANIPULATOR)
base_1_S_SMOTE_test<- base_1_escal_SMOTE_test%>%select(DSRI_S,GMI_S,AQI_S,SGI_S,DEPI_S,SGAI_S,ACCR_S,LEVI_S,C.MANIPULATOR)
base_1_S_SMOTE_test$C.MANIPULATOR <- as.factor(base_1_escal_SMOTE_test$C.MANIPULATOR)
set.seed(1920)
datos_entrenamiento<-base_1_S_u17_train
datos_prueba<-base_1_S_u17_test
modelo = svm(C.MANIPULATOR ~., kernel = "polynomial", data = datos_entrenamiento)
prediccion_train = predict(modelo, datos_entrenamiento)
mc_train = caret::confusionMatrix(table(datos_entrenamiento$C.MANIPULATOR,prediccion_train))
mc_train$table
resultados <- data.frame(mc_train$overall[['Accuracy']], mc_train$byClass[['Sensitivity']],
mc_train$byClass[['Specificity']], mc_train$overall[['Kappa']],
1 - mc_train$overall[['Accuracy']])
colnames(resultados) <- c("Exactitud","Sensibilidad","Especificidad","Kappa","Tasa de error")
kableExtra::kable(resultados,format='latex')%>%
kable_styling(bootstrap_options = "striped",
font_size = 8,full_width = F,latex_options = "HOLD_position")
prediccion_test = predict(modelo, datos_prueba)
mc_test = caret::confusionMatrix(table(datos_prueba$C.MANIPULATOR,prediccion_test))
mc_test$table
resultados <- data.frame(mc_test$overall[['Accuracy']], mc_test$byClass[['Sensitivity']],
mc_test$byClass[['Specificity']], mc_test$overall[['Kappa']],
1 - mc_test$overall[['Accuracy']])
colnames(resultados) <- c("Exactitud","Sensibilidad","Especificidad","Kappa","Tasa de error")
kableExtra::kable(resultados,format='latex')%>%
kable_styling(bootstrap_options = "striped",
font_size = 8,full_width = F,latex_options = "HOLD_position")
View(mc_train)
library(e1071)
library(dplyr)
library(caret)
library(kableExtra)
library(ROCR)
library(neuralnet)
#17
base_1_escal_u17_train<-read.csv2("../7_datasets/base_1_escal_us17_train.csv",sep =";",header=TRUE,dec=",")
base_1_escal_u17_test<-read.csv2("../7_datasets/base_1_escal_us17_test.csv",sep =";",header=TRUE,dec=",")
#Escalados
base_1_S_u17_train<- base_1_escal_u17_train%>%select(DSRI_S,GMI_S,AQI_S,SGI_S,DEPI_S,SGAI_S,ACCR_S,LEVI_S,C.MANIPULATOR)
base_1_S_u17_train$C.MANIPULATOR<-as.factor(base_1_escal_u17_train$C.MANIPULATOR)
base_1_S_u17_test<- base_1_escal_u17_test%>%select(DSRI_S,GMI_S,AQI_S,SGI_S,DEPI_S,SGAI_S,ACCR_S,LEVI_S,C.MANIPULATOR)
base_1_S_u17_test$C.MANIPULATOR <- as.factor(base_1_escal_u17_test$C.MANIPULATOR)
#SMOTE
base_1_escal_SMOTE_train<-read.csv2("../7_datasets/base_1_escal_SMOTE_train.csv",sep =";",header=TRUE,dec=",")
base_1_escal_SMOTE_test<-read.csv2("../7_datasets/base_1_escal_SMOTE_test.csv",sep =";",header=TRUE,dec=",")
#Escalados
base_1_S_SMOTE_train<- base_1_escal_SMOTE_train%>%select(DSRI_S,GMI_S,AQI_S,SGI_S,DEPI_S,SGAI_S,ACCR_S,LEVI_S,C.MANIPULATOR)
base_1_S_SMOTE_train$C.MANIPULATOR<-as.factor(base_1_escal_SMOTE_train$C.MANIPULATOR)
base_1_S_SMOTE_test<- base_1_escal_SMOTE_test%>%select(DSRI_S,GMI_S,AQI_S,SGI_S,DEPI_S,SGAI_S,ACCR_S,LEVI_S,C.MANIPULATOR)
base_1_S_SMOTE_test$C.MANIPULATOR <- as.factor(base_1_escal_SMOTE_test$C.MANIPULATOR)
#base_1_S_u17_train
#base_1_S_u17_test
str(base_1_S_SMOTE_train)
#base_1_S_SMOTE_test
set.seed(1920)
datos_entrenamiento<-base_1_S_SMOTE_train
datos_prueba<-base_1_S_SMOTE_test
#modelo = svm(C.MANIPULATOR ~., kernel = "polynomial", data = datos_entrenamiento)
#prediccion_train = predict(modelo, datos_entrenamiento)
modelo = neuralnet(C.MANIPULATOR ~.,
data = datos_entrenamiento,
stepmax = 5000, lifesign = "full",
hidden = 8)
prediccion_train = compute(modelo, datos_entrenamiento[-9])
View(modelo)
datos_entrenamiento[-9]
datos_entrenamiento[-9]
prediccion_train = compute(modelo, datos_entrenamiento[-9])
datos_entrenamiento[-9]
compute(modelo, datos_entrenamiento[-9])
compute(modelo, datos_entrenamiento)
compute(modelo, datos_entrenamiento[-8])
library(e1071)
library(dplyr)
library(caret)
library(kableExtra)
library(ROCR)
library(neuralnet)
#17
base_1_escal_u17_train<-read.csv2("../7_datasets/base_1_escal_us17_train.csv",sep =";",header=TRUE,dec=",")
base_1_escal_u17_test<-read.csv2("../7_datasets/base_1_escal_us17_test.csv",sep =";",header=TRUE,dec=",")
#Escalados
base_1_S_u17_train<- base_1_escal_u17_train%>%select(DSRI_S,GMI_S,AQI_S,SGI_S,DEPI_S,SGAI_S,ACCR_S,LEVI_S,C.MANIPULATOR)
base_1_S_u17_train$C.MANIPULATOR<-as.factor(base_1_escal_u17_train$C.MANIPULATOR)
base_1_S_u17_test<- base_1_escal_u17_test%>%select(DSRI_S,GMI_S,AQI_S,SGI_S,DEPI_S,SGAI_S,ACCR_S,LEVI_S,C.MANIPULATOR)
base_1_S_u17_test$C.MANIPULATOR <- as.factor(base_1_escal_u17_test$C.MANIPULATOR)
#SMOTE
base_1_escal_SMOTE_train<-read.csv2("../7_datasets/base_1_escal_SMOTE_train.csv",sep =";",header=TRUE,dec=",")
base_1_escal_SMOTE_test<-read.csv2("../7_datasets/base_1_escal_SMOTE_test.csv",sep =";",header=TRUE,dec=",")
#Escalados
base_1_S_SMOTE_train<- base_1_escal_SMOTE_train%>%select(DSRI_S,GMI_S,AQI_S,SGI_S,DEPI_S,SGAI_S,ACCR_S,LEVI_S,C.MANIPULATOR)
base_1_S_SMOTE_train$C.MANIPULATOR<-as.factor(base_1_escal_SMOTE_train$C.MANIPULATOR)
base_1_S_SMOTE_test<- base_1_escal_SMOTE_test%>%select(DSRI_S,GMI_S,AQI_S,SGI_S,DEPI_S,SGAI_S,ACCR_S,LEVI_S,C.MANIPULATOR)
base_1_S_SMOTE_test$C.MANIPULATOR <- as.factor(base_1_escal_SMOTE_test$C.MANIPULATOR)
compute(modelo, datos_entrenamiento[-8])
compute(modelo, as.matrix(datos_entrenamiento[-9]))
as.matrix(datos_entrenamiento[-9]))
as.matrix(datos_entrenamiento[-9])
compute(modelo,as.matrix(datos_entrenamiento[-9]))
set.seed(1920)
datos_entrenamiento<-base_1_S_SMOTE_train
datos_prueba<-base_1_S_SMOTE_test
#modelo = svm(C.MANIPULATOR ~., kernel = "polynomial", data = datos_entrenamiento)
#prediccion_train = predict(modelo, datos_entrenamiento)
modelo = neuralnet(C.MANIPULATOR ~.,
data = datos_entrenamiento,
stepmax = 5000, lifesign = "full",
hidden = 8)
#prediccion_train = compute(modelo, datos_entrenamiento[-9])
#mc_train = caret::confusionMatrix(table(datos_entrenamiento$C.MANIPULATOR,prediccion_train))
#mc_train$table
#resultados <- data.frame(mc_train$overall[['Accuracy']], mc_train$byClass[['Sensitivity']],
#                         mc_train$byClass[['Specificity']], mc_train$overall[['Kappa']],
#                         1 - mc_train$overall[['Accuracy']])
#colnames(resultados) <- c("Exactitud","Sensibilidad","Especificidad","Kappa","Tasa de error")
#kableExtra::kable(resultados,format='latex')%>%
#      kable_styling(bootstrap_options = "striped",
#      font_size = 8,full_width = F,latex_options = "HOLD_position")
#prediccion_test = predict(modelo, datos_prueba)
#mc_test = caret::confusionMatrix(table(datos_prueba$C.MANIPULATOR,prediccion_test))
#mc_test$table
#resultados <- data.frame(mc_test$overall[['Accuracy']], mc_test$byClass[['Sensitivity']],
#                         mc_test$byClass[['Specificity']], mc_test$overall[['Kappa']],
#                         1 - mc_test$overall[['Accuracy']])
#colnames(resultados) <- c("Exactitud","Sensibilidad","Especificidad","Kappa","Tasa de error")
#kableExtra::kable(resultados,format='latex')%>%
#      kable_styling(bootstrap_options = "striped",
#      font_size = 8,full_width = F,latex_options = "HOLD_position")
set.seed(1920)
datos_entrenamiento<-base_1_S_SMOTE_train
datos_prueba<-base_1_S_SMOTE_test
#modelo = svm(C.MANIPULATOR ~., kernel = "polynomial", data = datos_entrenamiento)
#prediccion_train = predict(modelo, datos_entrenamiento)
modelo = neuralnet(C.MANIPULATOR ~.,
data = datos_entrenamiento,
stepmax = 5000, lifesign = "full",
hidden = 9)
#prediccion_train = compute(modelo, datos_entrenamiento[-9])
#mc_train = caret::confusionMatrix(table(datos_entrenamiento$C.MANIPULATOR,prediccion_train))
#mc_train$table
#resultados <- data.frame(mc_train$overall[['Accuracy']], mc_train$byClass[['Sensitivity']],
#                         mc_train$byClass[['Specificity']], mc_train$overall[['Kappa']],
#                         1 - mc_train$overall[['Accuracy']])
#colnames(resultados) <- c("Exactitud","Sensibilidad","Especificidad","Kappa","Tasa de error")
#kableExtra::kable(resultados,format='latex')%>%
#      kable_styling(bootstrap_options = "striped",
#      font_size = 8,full_width = F,latex_options = "HOLD_position")
#prediccion_test = predict(modelo, datos_prueba)
#mc_test = caret::confusionMatrix(table(datos_prueba$C.MANIPULATOR,prediccion_test))
#mc_test$table
#resultados <- data.frame(mc_test$overall[['Accuracy']], mc_test$byClass[['Sensitivity']],
#                         mc_test$byClass[['Specificity']], mc_test$overall[['Kappa']],
#                         1 - mc_test$overall[['Accuracy']])
#colnames(resultados) <- c("Exactitud","Sensibilidad","Especificidad","Kappa","Tasa de error")
#kableExtra::kable(resultados,format='latex')%>%
#      kable_styling(bootstrap_options = "striped",
#      font_size = 8,full_width = F,latex_options = "HOLD_position")
set.seed(1920)
datos_entrenamiento<-base_1_S_SMOTE_train
datos_prueba<-base_1_S_SMOTE_test
#modelo = svm(C.MANIPULATOR ~., kernel = "polynomial", data = datos_entrenamiento)
#prediccion_train = predict(modelo, datos_entrenamiento)
modelo = neuralnet(C.MANIPULATOR ~.,
data = datos_entrenamiento,
stepmax = 10000, lifesign = "full",
hidden = 8)
#prediccion_train = compute(modelo, datos_entrenamiento[-9])
#mc_train = caret::confusionMatrix(table(datos_entrenamiento$C.MANIPULATOR,prediccion_train))
#mc_train$table
#resultados <- data.frame(mc_train$overall[['Accuracy']], mc_train$byClass[['Sensitivity']],
#                         mc_train$byClass[['Specificity']], mc_train$overall[['Kappa']],
#                         1 - mc_train$overall[['Accuracy']])
#colnames(resultados) <- c("Exactitud","Sensibilidad","Especificidad","Kappa","Tasa de error")
#kableExtra::kable(resultados,format='latex')%>%
#      kable_styling(bootstrap_options = "striped",
#      font_size = 8,full_width = F,latex_options = "HOLD_position")
#prediccion_test = predict(modelo, datos_prueba)
#mc_test = caret::confusionMatrix(table(datos_prueba$C.MANIPULATOR,prediccion_test))
#mc_test$table
#resultados <- data.frame(mc_test$overall[['Accuracy']], mc_test$byClass[['Sensitivity']],
#                         mc_test$byClass[['Specificity']], mc_test$overall[['Kappa']],
#                         1 - mc_test$overall[['Accuracy']])
#colnames(resultados) <- c("Exactitud","Sensibilidad","Especificidad","Kappa","Tasa de error")
#kableExtra::kable(resultados,format='latex')%>%
#      kable_styling(bootstrap_options = "striped",
#      font_size = 8,full_width = F,latex_options = "HOLD_position")
set.seed(1920)
datos_entrenamiento<-base_1_S_SMOTE_train
datos_prueba<-base_1_S_SMOTE_test
#modelo = svm(C.MANIPULATOR ~., kernel = "polynomial", data = datos_entrenamiento)
#prediccion_train = predict(modelo, datos_entrenamiento)
modelo = neuralnet(C.MANIPULATOR ~.,
data = datos_entrenamiento,
stepmax = 50000, lifesign = "full",
hidden = 8)
#prediccion_train = compute(modelo, datos_entrenamiento[-9])
#mc_train = caret::confusionMatrix(table(datos_entrenamiento$C.MANIPULATOR,prediccion_train))
#mc_train$table
#resultados <- data.frame(mc_train$overall[['Accuracy']], mc_train$byClass[['Sensitivity']],
#                         mc_train$byClass[['Specificity']], mc_train$overall[['Kappa']],
#                         1 - mc_train$overall[['Accuracy']])
#colnames(resultados) <- c("Exactitud","Sensibilidad","Especificidad","Kappa","Tasa de error")
#kableExtra::kable(resultados,format='latex')%>%
#      kable_styling(bootstrap_options = "striped",
#      font_size = 8,full_width = F,latex_options = "HOLD_position")
#prediccion_test = predict(modelo, datos_prueba)
#mc_test = caret::confusionMatrix(table(datos_prueba$C.MANIPULATOR,prediccion_test))
#mc_test$table
#resultados <- data.frame(mc_test$overall[['Accuracy']], mc_test$byClass[['Sensitivity']],
#                         mc_test$byClass[['Specificity']], mc_test$overall[['Kappa']],
#                         1 - mc_test$overall[['Accuracy']])
#colnames(resultados) <- c("Exactitud","Sensibilidad","Especificidad","Kappa","Tasa de error")
#kableExtra::kable(resultados,format='latex')%>%
#      kable_styling(bootstrap_options = "striped",
#      font_size = 8,full_width = F,latex_options = "HOLD_position")
setwd("D:/Ronald Fernando/dauruxu/articulosDelProyecto/articulo_TG1")
setwd("D:/Ronald Fernando/dauruxu/articulosDelProyecto/articulo_TG1")
