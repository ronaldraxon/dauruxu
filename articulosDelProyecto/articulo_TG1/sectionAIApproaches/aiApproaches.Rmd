---
title: "IA activities emotion recog"
author: "Ronald"
output: pdf_document
---

# Artificial intelligence in activites and emotion recognition
  
As could be evidenced in the previous section, some activities and emotions can be captured by cameras and whose analysis can constitute a significant source of data in the form of metrics and indicators to facilitate psychosocial evaluation. However, data extraction and its interpretation constitute a technological challenge that has been widely addressed by disciplines such as computer vision [@ABBAS2017], wich main tasks focus on the Acquisition, processing, analysis, and understanding real-world images. This discipline has brought new opportunities to take advantage of image data using machine learning algorithms and, in some cases, supporting itself in high-performance computing systems[].

Unlike object recognition using static images, activity recognition involves analyzing and processing frames at a specific time interval. When trying to identify an action such as lifting a leg to take a step, it constitutes a series of images that allow identifying this action. By repeating this action for a prolonged period, the development of the activity "walking" would be obtained. Within the literature, we can found various definitions of the term activity. Some of them correspond to the physical point of view, and others correspond to the psychological point of view. For this work, an activity will be defined as a repeated and recurring composition of actions in a given period.

## Actions and Activities Recognition

Among the recent approaches, we can find methods that guide the classification of actions once they have been carried out. According to this, there are works were key poses are distinguished for the identification of an action. In this case, deep neural networks are used to extract the features of the images, and then they are interpreted using an Adaboost classifier, to finally classify the actions using their proposed weighted local naive Bayes nearest neighbor classifier. Works such as  Sahoo's [@SAHOO2019524] employ methods of detecting points of interest by proposing a local maximum of difference. In the article published by Somandundaram [@SOMASUNDARAM20141], it is proposed a new global Spatio-temporal self-similarity measure to score saliency using the ideas of dictionary learning and sparse coding. On the other hand, there are works whose objective is to carry out the early detection of activities or recognizing the category of an ongoing human action from a video stream. From this perspective, we can find works such as Wang's [@WANG201824], whose method works on a recurrent neural network that computes the probability of a frame to be the starting point by comparing the dynamics of the actions before and after the frame stand out.

Within this project, the use of activity detection with techniques and algorithms similar to those used in the mentioned articles becomes relevant. However, the use of abnormality detection techniques is highly engaging as we can detect significant deviation from an individualâ€™s usual behavioral routine. Works such as [@YAHAYA2019105613], highlights the identification of abnormality in activities of daily living using ensemble models. The detection of anomalies employing video images have been widely addressed during the last 20 years, and they address tasks such as the detection of risk situations such as outbreaks, detection of abandoned objects or objects located in particular areas, detection of falls of people, among others [@Tripathi2017] [@BENMABROUK2018480]. Several of these detection objectives are relevant to the detection of activities related to psychosocial risk factors, to the extent that the identification of routines can be recorded and identified, in order to determine a change in these routines later. We can evidence an example of its application in works such as that of Kim [@KIM2017], in which fuzzy clustering is used to identify patterns in smoking cessation. This particular example could be used to provide information to questionnaires, such as the survey of personal and social development mentioned in the previous section.

Another relevant topic is gait analysis. Among the authors who have contributed significantly is Dr. Jacquelin Perry [@PERRY2010]. Gait analysis consists of detecting and recording human movements taking into account characteristics such as step length, cadence, speed, dynamic base, line of progression, foot angle, among others. This area of research has contributed to the construction of models for the analysis of brain problems from displacement [@FLUX2020102585]. Other works such as Kitade's [@KITADE2020] use gait analysis to study the expressive, appellative, or communicative meaning of body movements in the diagnosis of musculoskeletal disorders and which are highly relevant in the evaluation of psychosocial risk.
   
In addition to the exposed approaches, we can find jobs with application results used mostly in the automotive industry. This scenario corresponds to the detection of drowsiness in drivers for accident prevention. Some approximations of this type are the usage of an enhanced image processing technique inspired by the human visual system mentioned in Hedyeh's work [@HEDYEH2016], or the usage mixed-effect ordered logit model considering a time- cumulative effect proposed by Zhang [@ZHANG2020100114].  

## Emotion Recognition

In the same way, we have mentioned some techniques to detect activities; we intend to identify emotions evaluated with psycho-social questionnaires and which can be experienced at work or a university as an academic environment. The emotions recognition, have become a widely explored research area with contributions such as the Hourglass of Emotions[@CAMBRIA2011] as this work proposes a  biologically-inspired and psychologically-motivated categorization for emotions. Also, some approaches have shown challenges alternatives to infer specific medical conditions by detecting emotional state changes from facial cues [@BARRET2019][@GIANNAKAKIS201789]. Nevertheless, most of these approaches as its seen in works such as Bevilacqua's [@BEVILACQUA2018] or Jain's [@JAIN2019] requires a face close up to capture those images that will be processed later. As emotions can take place in several situations, to gather emotional content expressed by the body becomes an alternative that we intend to explore.

There is some research aimed at automating emotion recognition. However, this type of approach entails a challenge that constitutes the representation of body gestures. Works such as that of Piana [@PIANA2016], define a series of characteristics called gesture primitives. The association of movements is made by relating the emotions Anger, fear, happiness, disgust, sadness, and surprise that will be interpreted by in an architecture that extracts characteristics from low to a high level using mechanisms based on sparse dictionary learning, which can finally be classified by an SVM. Another similar work is that of Ferdous Ahmed [@AHMED2019], who uses previously conceived concepts such as Gait Analysis. In this case, the association of body movements with basic emotions is also performed by identifying emotions in poses and actions such as sitting or walking. Another notable difference is the conformation of a group of characteristics appropriate for the classification that is carried out employing assembly techniques and model stacking.

A technique frequently used in the identification of emotions is the extraction of characteristics through Deep Learning, using variation in the convolutions that develop in its topology. We previously mentioned emotion recognition using facial cues and several papers and reviews related to it[@KO2018][@JAN2014]. Nevertheless, works such as Santhoshkumar's [@SANTHOSHKUMAR2019158] not only address concepts of kinesics but also employ the extraction of saliency information at multiple scales and the Block Average Intensity Value that reflects changes in the image after a systematic segmentation of the photograms. 

Within the review of the mentioned articles, it was possible to identify techniques for the extraction of characteristics and their selection using genetic algorithms. Likewise, classification mechanisms and public databases used for experimental validation were identified. One of the most significant contributions is the use of hardware components such as Microsoft Kinect and libraries for the extraction of characteristics of body gestures from the identification of limbs and joint points. In the next section, some libraries will be explored, and experimentation will be carried out in order to identify their features and use potential.



