{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Hello World of Deep Learning with Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Comecemos con algo simple: una función deterministica\n",
    "\n",
    "float hw_function(float x){\n",
    "    float y = (2 * x) - 1;\n",
    "    return y;\n",
    "}\n",
    "\n",
    "Como entrenamos una red para aprender esta función? \n",
    "\n",
    "Entrenando una red con suficientes datos (Xs, Ys), el sistema deberia poder encontrar la relación. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definamos la red mas sencilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilemos el modelo para que evalue con el MSE y optimice el suguiente paso con gradientes estocasticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "entreguemos algunos datos al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "entrenemos la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6 samples\n",
      "Epoch 1/500\n",
      "6/6 [==============================] - 1s 148ms/sample - loss: 46.9976\n",
      "Epoch 2/500\n",
      "6/6 [==============================] - 0s 1000us/sample - loss: 37.3580\n",
      "Epoch 3/500\n",
      "6/6 [==============================] - 0s 666us/sample - loss: 29.7662\n",
      "Epoch 4/500\n",
      "6/6 [==============================] - 0s 666us/sample - loss: 23.7856\n",
      "Epoch 5/500\n",
      "6/6 [==============================] - 0s 666us/sample - loss: 19.0728\n",
      "Epoch 6/500\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 15.3577\n",
      "Epoch 7/500\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 12.4275\n",
      "Epoch 8/500\n",
      "6/6 [==============================] - 0s 666us/sample - loss: 10.1151\n",
      "Epoch 9/500\n",
      "6/6 [==============================] - 0s 666us/sample - loss: 8.2889\n",
      "Epoch 10/500\n",
      "6/6 [==============================] - 0s 836us/sample - loss: 6.8454\n",
      "Epoch 11/500\n",
      "6/6 [==============================] - 0s 833us/sample - loss: 5.7030\n",
      "Epoch 12/500\n",
      "6/6 [==============================] - 0s 667us/sample - loss: 4.7977\n",
      "Epoch 13/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 4.0791\n",
      "Epoch 14/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 3.5074\n",
      "Epoch 15/500\n",
      "6/6 [==============================] - 0s 667us/sample - loss: 3.0516\n",
      "Epoch 16/500\n",
      "6/6 [==============================] - 0s 667us/sample - loss: 2.6869\n",
      "Epoch 17/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 2.3942\n",
      "Epoch 18/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 2.1581\n",
      "Epoch 19/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 1.9667\n",
      "Epoch 20/500\n",
      "6/6 [==============================] - 0s 666us/sample - loss: 1.8106\n",
      "Epoch 21/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 1.6824\n",
      "Epoch 22/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 1.5762\n",
      "Epoch 23/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 1.4875\n",
      "Epoch 24/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 1.4126\n",
      "Epoch 25/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 1.3487\n",
      "Epoch 26/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 1.2936\n",
      "Epoch 27/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 1.2454\n",
      "Epoch 28/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 1.2029\n",
      "Epoch 29/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 1.1648\n",
      "Epoch 30/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 1.1304\n",
      "Epoch 31/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 1.0989\n",
      "Epoch 32/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 1.0698\n",
      "Epoch 33/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 1.0427\n",
      "Epoch 34/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.0173\n",
      "Epoch 35/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.9932\n",
      "Epoch 36/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.9703\n",
      "Epoch 37/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.9484\n",
      "Epoch 38/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.9274\n",
      "Epoch 39/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.9071\n",
      "Epoch 40/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.8875\n",
      "Epoch 41/500\n",
      "6/6 [==============================] - 0s 666us/sample - loss: 0.8685\n",
      "Epoch 42/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.8501\n",
      "Epoch 43/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.8322\n",
      "Epoch 44/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.8147\n",
      "Epoch 45/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.7977\n",
      "Epoch 46/500\n",
      "6/6 [==============================] - 0s 491us/sample - loss: 0.7811\n",
      "Epoch 47/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.7649\n",
      "Epoch 48/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.7490\n",
      "Epoch 49/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.7335\n",
      "Epoch 50/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.7184\n",
      "Epoch 51/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.7035\n",
      "Epoch 52/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.6890\n",
      "Epoch 53/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.6748\n",
      "Epoch 54/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.6610\n",
      "Epoch 55/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.6473\n",
      "Epoch 56/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.6340\n",
      "Epoch 57/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.6210\n",
      "Epoch 58/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.6082\n",
      "Epoch 59/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.5957\n",
      "Epoch 60/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.5835\n",
      "Epoch 61/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.5715\n",
      "Epoch 62/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.5597\n",
      "Epoch 63/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.5482\n",
      "Epoch 64/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.5370\n",
      "Epoch 65/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.5259\n",
      "Epoch 66/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.5151\n",
      "Epoch 67/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.5046\n",
      "Epoch 68/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.4942\n",
      "Epoch 69/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.4840\n",
      "Epoch 70/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.4741\n",
      "Epoch 71/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.4644\n",
      "Epoch 72/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.4548\n",
      "Epoch 73/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.4455\n",
      "Epoch 74/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.4363\n",
      "Epoch 75/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.4274\n",
      "Epoch 76/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.4186\n",
      "Epoch 77/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.4100\n",
      "Epoch 78/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.4016\n",
      "Epoch 79/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.3933\n",
      "Epoch 80/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.3852\n",
      "Epoch 81/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.3773\n",
      "Epoch 82/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.3696\n",
      "Epoch 83/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.3620\n",
      "Epoch 84/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.3545\n",
      "Epoch 85/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.3473\n",
      "Epoch 86/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.3401\n",
      "Epoch 87/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.3331\n",
      "Epoch 88/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.3263\n",
      "Epoch 89/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.3196\n",
      "Epoch 90/500\n",
      "6/6 [==============================] - 0s 501us/sample - loss: 0.3130\n",
      "Epoch 91/500\n",
      "6/6 [==============================] - 0s 499us/sample - loss: 0.3066\n",
      "Epoch 92/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.3003\n",
      "Epoch 93/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.2941\n",
      "Epoch 94/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.2881\n",
      "Epoch 95/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.2822\n",
      "Epoch 96/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.2764\n",
      "Epoch 97/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.2707\n",
      "Epoch 98/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.2651\n",
      "Epoch 99/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.2597\n",
      "Epoch 100/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.2544\n",
      "Epoch 101/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.2491\n",
      "Epoch 102/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.2440\n",
      "Epoch 103/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.2390\n",
      "Epoch 104/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.2341\n",
      "Epoch 105/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.2293\n",
      "Epoch 106/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.2246\n",
      "Epoch 107/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.2200\n",
      "Epoch 108/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.2155\n",
      "Epoch 109/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.2110\n",
      "Epoch 110/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.2067\n",
      "Epoch 111/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.2024\n",
      "Epoch 112/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.1983\n",
      "Epoch 113/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.1942\n",
      "Epoch 114/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.1902\n",
      "Epoch 115/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.1863\n",
      "Epoch 116/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.1825\n",
      "Epoch 117/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.1787\n",
      "Epoch 118/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.1751\n",
      "Epoch 119/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.1715\n",
      "Epoch 120/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.1680\n",
      "Epoch 121/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.1645\n",
      "Epoch 122/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.1611\n",
      "Epoch 123/500\n",
      "6/6 [==============================] - 0s 332us/sample - loss: 0.1578\n",
      "Epoch 124/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.1546\n",
      "Epoch 125/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.1514\n",
      "Epoch 126/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.1483\n",
      "Epoch 127/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.1452\n",
      "Epoch 128/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.1423\n",
      "Epoch 129/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.1393\n",
      "Epoch 130/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.1365\n",
      "Epoch 131/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.1337\n",
      "Epoch 132/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.1309\n",
      "Epoch 133/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.1282\n",
      "Epoch 134/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.1256\n",
      "Epoch 135/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.1230\n",
      "Epoch 136/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.1205\n",
      "Epoch 137/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.1180\n",
      "Epoch 138/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.1156\n",
      "Epoch 139/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.1132\n",
      "Epoch 140/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.1109\n",
      "Epoch 141/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.1086\n",
      "Epoch 142/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.1064\n",
      "Epoch 143/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.1042\n",
      "Epoch 144/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.1021\n",
      "Epoch 145/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.1000\n",
      "Epoch 146/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0979\n",
      "Epoch 147/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0959\n",
      "Epoch 148/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0939\n",
      "Epoch 149/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0920\n",
      "Epoch 150/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0901\n",
      "Epoch 151/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0883\n",
      "Epoch 152/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0864\n",
      "Epoch 153/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0847\n",
      "Epoch 154/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0829\n",
      "Epoch 155/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0812\n",
      "Epoch 156/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0796\n",
      "Epoch 157/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0779\n",
      "Epoch 158/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0763\n",
      "Epoch 159/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0748\n",
      "Epoch 160/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0732\n",
      "Epoch 161/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0717\n",
      "Epoch 162/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0702\n",
      "Epoch 163/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0688\n",
      "Epoch 164/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0674\n",
      "Epoch 165/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0660\n",
      "Epoch 166/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0646\n",
      "Epoch 167/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0633\n",
      "Epoch 168/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0620\n",
      "Epoch 169/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0607\n",
      "Epoch 170/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0595\n",
      "Epoch 171/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0583\n",
      "Epoch 172/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0571\n",
      "Epoch 173/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0559\n",
      "Epoch 174/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0548\n",
      "Epoch 175/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0536\n",
      "Epoch 176/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0525\n",
      "Epoch 177/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0515\n",
      "Epoch 178/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0504\n",
      "Epoch 179/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0494\n",
      "Epoch 180/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0483\n",
      "Epoch 181/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0474\n",
      "Epoch 182/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0464\n",
      "Epoch 183/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0454\n",
      "Epoch 184/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0445\n",
      "Epoch 185/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0436\n",
      "Epoch 186/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0427\n",
      "Epoch 187/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0418\n",
      "Epoch 188/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0410\n",
      "Epoch 189/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0401\n",
      "Epoch 190/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0393\n",
      "Epoch 191/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0385\n",
      "Epoch 192/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0377\n",
      "Epoch 193/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0369\n",
      "Epoch 194/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0362\n",
      "Epoch 195/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0354\n",
      "Epoch 196/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0347\n",
      "Epoch 197/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0340\n",
      "Epoch 198/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0333\n",
      "Epoch 199/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0326\n",
      "Epoch 200/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0319\n",
      "Epoch 201/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0313\n",
      "Epoch 202/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0306\n",
      "Epoch 203/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0300\n",
      "Epoch 204/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0294\n",
      "Epoch 205/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0288\n",
      "Epoch 206/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0282\n",
      "Epoch 207/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0276\n",
      "Epoch 208/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0270\n",
      "Epoch 209/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0265\n",
      "Epoch 210/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0259\n",
      "Epoch 211/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0254\n",
      "Epoch 212/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0249\n",
      "Epoch 213/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0244\n",
      "Epoch 214/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0239\n",
      "Epoch 215/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0234\n",
      "Epoch 216/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0229\n",
      "Epoch 217/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0224\n",
      "Epoch 218/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0220\n",
      "Epoch 219/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0215\n",
      "Epoch 220/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0211\n",
      "Epoch 221/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0206\n",
      "Epoch 222/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0202\n",
      "Epoch 223/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0198\n",
      "Epoch 224/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0194\n",
      "Epoch 225/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0190\n",
      "Epoch 226/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0186\n",
      "Epoch 227/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0182\n",
      "Epoch 228/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0179\n",
      "Epoch 229/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0175\n",
      "Epoch 230/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0171\n",
      "Epoch 231/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0168\n",
      "Epoch 232/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0164\n",
      "Epoch 233/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0161\n",
      "Epoch 234/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0158\n",
      "Epoch 235/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0154\n",
      "Epoch 236/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0151\n",
      "Epoch 237/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0148\n",
      "Epoch 238/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0145\n",
      "Epoch 239/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0142\n",
      "Epoch 240/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0139\n",
      "Epoch 241/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0136\n",
      "Epoch 242/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0134\n",
      "Epoch 243/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0131\n",
      "Epoch 244/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0128\n",
      "Epoch 245/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0125\n",
      "Epoch 246/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0123\n",
      "Epoch 247/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0120\n",
      "Epoch 248/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0118\n",
      "Epoch 249/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0115\n",
      "Epoch 250/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0113\n",
      "Epoch 251/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0111\n",
      "Epoch 252/500\n",
      "6/6 [==============================] - 0s 334us/sample - loss: 0.0108\n",
      "Epoch 253/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0106\n",
      "Epoch 254/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0104\n",
      "Epoch 255/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0102\n",
      "Epoch 256/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0100\n",
      "Epoch 257/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0098\n",
      "Epoch 258/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0096\n",
      "Epoch 259/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0094\n",
      "Epoch 260/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0092\n",
      "Epoch 261/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0090\n",
      "Epoch 262/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0088\n",
      "Epoch 263/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0086\n",
      "Epoch 264/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0085\n",
      "Epoch 265/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0083\n",
      "Epoch 266/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0081\n",
      "Epoch 267/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0079\n",
      "Epoch 268/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0078\n",
      "Epoch 269/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0076\n",
      "Epoch 270/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0075\n",
      "Epoch 271/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0073\n",
      "Epoch 272/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0072\n",
      "Epoch 273/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0070\n",
      "Epoch 274/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0069\n",
      "Epoch 275/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0067\n",
      "Epoch 276/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0066\n",
      "Epoch 277/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0065\n",
      "Epoch 278/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0063\n",
      "Epoch 279/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0062\n",
      "Epoch 280/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0061\n",
      "Epoch 281/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0059\n",
      "Epoch 282/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0058\n",
      "Epoch 283/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0057\n",
      "Epoch 284/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0056\n",
      "Epoch 285/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0055\n",
      "Epoch 286/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0054\n",
      "Epoch 287/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0052\n",
      "Epoch 288/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0051\n",
      "Epoch 289/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0050\n",
      "Epoch 290/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0049\n",
      "Epoch 291/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0048\n",
      "Epoch 292/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0047\n",
      "Epoch 293/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0046\n",
      "Epoch 294/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0045\n",
      "Epoch 295/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0044\n",
      "Epoch 296/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0044\n",
      "Epoch 297/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0043\n",
      "Epoch 298/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0042\n",
      "Epoch 299/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0041\n",
      "Epoch 300/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0040\n",
      "Epoch 301/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0039\n",
      "Epoch 302/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0038\n",
      "Epoch 303/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0038\n",
      "Epoch 304/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0037\n",
      "Epoch 305/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0036\n",
      "Epoch 306/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0035\n",
      "Epoch 307/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0035\n",
      "Epoch 308/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0034\n",
      "Epoch 309/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0033\n",
      "Epoch 310/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0033\n",
      "Epoch 311/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0032\n",
      "Epoch 312/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0031\n",
      "Epoch 313/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0031\n",
      "Epoch 314/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0030\n",
      "Epoch 315/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0029\n",
      "Epoch 316/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0029\n",
      "Epoch 317/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0028\n",
      "Epoch 318/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0028\n",
      "Epoch 319/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0027\n",
      "Epoch 320/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0026\n",
      "Epoch 321/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0026\n",
      "Epoch 322/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0025\n",
      "Epoch 323/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0025\n",
      "Epoch 324/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0024\n",
      "Epoch 325/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0024\n",
      "Epoch 326/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0023\n",
      "Epoch 327/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0023\n",
      "Epoch 328/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0022\n",
      "Epoch 329/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0022\n",
      "Epoch 330/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0021\n",
      "Epoch 331/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0021\n",
      "Epoch 332/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0021\n",
      "Epoch 333/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0020\n",
      "Epoch 334/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0020\n",
      "Epoch 335/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0019\n",
      "Epoch 336/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0019\n",
      "Epoch 337/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0019\n",
      "Epoch 338/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0018\n",
      "Epoch 339/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0018\n",
      "Epoch 340/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0017\n",
      "Epoch 341/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0017\n",
      "Epoch 342/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0017\n",
      "Epoch 343/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0016\n",
      "Epoch 344/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0016\n",
      "Epoch 345/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0016\n",
      "Epoch 346/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0015\n",
      "Epoch 347/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0015\n",
      "Epoch 348/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0015\n",
      "Epoch 349/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0014\n",
      "Epoch 350/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0014\n",
      "Epoch 351/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0014\n",
      "Epoch 352/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0014\n",
      "Epoch 353/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0013\n",
      "Epoch 354/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0013\n",
      "Epoch 355/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0013\n",
      "Epoch 356/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0013\n",
      "Epoch 357/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0012\n",
      "Epoch 358/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0012\n",
      "Epoch 359/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0012\n",
      "Epoch 360/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0012\n",
      "Epoch 361/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0011\n",
      "Epoch 362/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0011\n",
      "Epoch 363/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0011\n",
      "Epoch 364/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0011\n",
      "Epoch 365/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 0.0010\n",
      "Epoch 366/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 0.0010\n",
      "Epoch 367/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 9.9731e-04\n",
      "Epoch 368/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 9.7683e-04\n",
      "Epoch 369/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 9.5676e-04\n",
      "Epoch 370/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 9.3711e-04\n",
      "Epoch 371/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 9.1786e-04\n",
      "Epoch 372/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 8.9900e-04\n",
      "Epoch 373/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 8.8054e-04\n",
      "Epoch 374/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 8.6245e-04\n",
      "Epoch 375/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 8.4474e-04\n",
      "Epoch 376/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 8.2739e-04\n",
      "Epoch 377/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 8.1039e-04\n",
      "Epoch 378/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 7.9375e-04\n",
      "Epoch 379/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 7.7744e-04\n",
      "Epoch 380/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 7.6147e-04\n",
      "Epoch 381/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 7.4583e-04\n",
      "Epoch 382/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 7.3051e-04\n",
      "Epoch 383/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 7.1551e-04\n",
      "Epoch 384/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 7.0081e-04\n",
      "Epoch 385/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 6.8641e-04\n",
      "Epoch 386/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 6.7232e-04\n",
      "Epoch 387/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 6.5851e-04\n",
      "Epoch 388/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 6.4498e-04\n",
      "Epoch 389/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 6.3173e-04\n",
      "Epoch 390/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 6.1875e-04\n",
      "Epoch 391/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 6.0604e-04\n",
      "Epoch 392/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 5.9360e-04\n",
      "Epoch 393/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 5.8140e-04\n",
      "Epoch 394/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 5.6946e-04\n",
      "Epoch 395/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 5.5777e-04\n",
      "Epoch 396/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 5.4631e-04\n",
      "Epoch 397/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 5.3509e-04\n",
      "Epoch 398/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 5.2409e-04\n",
      "Epoch 399/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 5.1333e-04\n",
      "Epoch 400/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 5.0279e-04\n",
      "Epoch 401/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 4.9246e-04\n",
      "Epoch 402/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 4.8234e-04\n",
      "Epoch 403/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 4.7243e-04\n",
      "Epoch 404/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 4.6273e-04\n",
      "Epoch 405/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 4.5323e-04\n",
      "Epoch 406/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 4.4392e-04\n",
      "Epoch 407/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 4.3480e-04\n",
      "Epoch 408/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 4.2587e-04\n",
      "Epoch 409/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 4.1712e-04\n",
      "Epoch 410/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 4.0855e-04\n",
      "Epoch 411/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 4.0016e-04\n",
      "Epoch 412/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 3.9194e-04\n",
      "Epoch 413/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 3.8389e-04\n",
      "Epoch 414/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 3.7601e-04\n",
      "Epoch 415/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 3.6828e-04\n",
      "Epoch 416/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 3.6072e-04\n",
      "Epoch 417/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 3.5331e-04\n",
      "Epoch 418/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 3.4605e-04\n",
      "Epoch 419/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 3.3894e-04\n",
      "Epoch 420/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 3.3198e-04\n",
      "Epoch 421/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 3.2516e-04\n",
      "Epoch 422/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 3.1848e-04\n",
      "Epoch 423/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 3.1194e-04\n",
      "Epoch 424/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 3.0553e-04\n",
      "Epoch 425/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 2.9926e-04\n",
      "Epoch 426/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 2.9311e-04\n",
      "Epoch 427/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 2.8709e-04\n",
      "Epoch 428/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 2.8119e-04\n",
      "Epoch 429/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 2.7542e-04\n",
      "Epoch 430/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 2.6976e-04\n",
      "Epoch 431/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 2.6422e-04\n",
      "Epoch 432/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 2.5879e-04\n",
      "Epoch 433/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 2.5348e-04\n",
      "Epoch 434/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 2.4827e-04\n",
      "Epoch 435/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 2.4317e-04\n",
      "Epoch 436/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 2.3818e-04\n",
      "Epoch 437/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 2.3329e-04\n",
      "Epoch 438/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 2.2849e-04\n",
      "Epoch 439/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 2.2380e-04\n",
      "Epoch 440/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 2.1920e-04\n",
      "Epoch 441/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 2.1470e-04\n",
      "Epoch 442/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 2.1029e-04\n",
      "Epoch 443/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 2.0597e-04\n",
      "Epoch 444/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 2.0174e-04\n",
      "Epoch 445/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 1.9760e-04\n",
      "Epoch 446/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.9354e-04\n",
      "Epoch 447/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.8956e-04\n",
      "Epoch 448/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.8567e-04\n",
      "Epoch 449/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.8185e-04\n",
      "Epoch 450/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.7812e-04\n",
      "Epoch 451/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 1.7446e-04\n",
      "Epoch 452/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.7088e-04\n",
      "Epoch 453/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.6737e-04\n",
      "Epoch 454/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.6393e-04\n",
      "Epoch 455/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.6056e-04\n",
      "Epoch 456/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.5726e-04\n",
      "Epoch 457/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.5403e-04\n",
      "Epoch 458/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.5087e-04\n",
      "Epoch 459/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.4777e-04\n",
      "Epoch 460/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 1.4473e-04\n",
      "Epoch 461/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.4176e-04\n",
      "Epoch 462/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.3885e-04\n",
      "Epoch 463/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.3600e-04\n",
      "Epoch 464/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.3320e-04\n",
      "Epoch 465/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.3047e-04\n",
      "Epoch 466/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.2779e-04\n",
      "Epoch 467/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.2516e-04\n",
      "Epoch 468/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.2259e-04\n",
      "Epoch 469/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 1.2007e-04\n",
      "Epoch 470/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 1.1761e-04\n",
      "Epoch 471/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.1519e-04\n",
      "Epoch 472/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.1283e-04\n",
      "Epoch 473/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.1051e-04\n",
      "Epoch 474/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.0824e-04\n",
      "Epoch 475/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 1.0602e-04\n",
      "Epoch 476/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 1.0384e-04\n",
      "Epoch 477/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 1.0171e-04\n",
      "Epoch 478/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 9.9616e-05\n",
      "Epoch 479/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 9.7571e-05\n",
      "Epoch 480/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 9.5566e-05\n",
      "Epoch 481/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 9.3604e-05\n",
      "Epoch 482/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 9.1681e-05\n",
      "Epoch 483/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 8.9797e-05\n",
      "Epoch 484/500\n",
      "6/6 [==============================] - 0s 167us/sample - loss: 8.7953e-05\n",
      "Epoch 485/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 8.6146e-05\n",
      "Epoch 486/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 8.4377e-05\n",
      "Epoch 487/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 8.2645e-05\n",
      "Epoch 488/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 8.0947e-05\n",
      "Epoch 489/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 7.9285e-05\n",
      "Epoch 490/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 7.7655e-05\n",
      "Epoch 491/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 7.6060e-05\n",
      "Epoch 492/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 7.4498e-05\n",
      "Epoch 493/500\n",
      "6/6 [==============================] - 0s 500us/sample - loss: 7.2968e-05\n",
      "Epoch 494/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 7.1469e-05\n",
      "Epoch 495/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 7.0001e-05\n",
      "Epoch 496/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 6.8562e-05\n",
      "Epoch 497/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 6.7153e-05\n",
      "Epoch 498/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 6.5775e-05\n",
      "Epoch 499/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 6.4424e-05\n",
      "Epoch 500/500\n",
      "6/6 [==============================] - 0s 333us/sample - loss: 6.3100e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18e405e8108>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xs, ys, epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluemos la respuesta del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18.976824]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primera aproximación a \"Computer Vision\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a importar la base Fashion MNIST  del API de KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a importar datos de entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploremos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1697e65d648>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUDklEQVR4nO3da2yc1ZkH8P8z4/ElzjiJc3FCcAmXUJLCEqhJgFSUkkJDtNqQUioQYkFCG7QL3bbLBxDtquyXFUILCC277RrIElaFqlVBUBRRgrlkgZLGhJTcNgQSk5tjOzGxHcdjz+XZDx5aE3ye18w7M+/A+f8ky/Y8PjPHM/77nZnznnNEVUFEX36xqDtAROXBsBN5gmEn8gTDTuQJhp3IE1XlvLFqqdFa1JfzJom8ksIgRnRYxquFCruILAfwMIA4gMdU9T7r52tRjyWyLMxNEpFho7Y5awU/jReROID/AHA1gIUAbhCRhYVeHxGVVpjX7IsBfKCqe1R1BMCvAKwsTreIqNjChH0ugP1jvj+Qv+xTRGS1iLSLSHsawyFujojCCBP28d4E+My5t6raqqotqtqSQE2ImyOiMMKE/QCA5jHfnwrgULjuEFGphAn7JgDzReR0EakGcD2A54vTLSIqtoKH3lQ1IyJ3APg9Rofe1qjq9qL1jIiKKtQ4u6quA7CuSH0hohLi6bJEnmDYiTzBsBN5gmEn8gTDTuQJhp3IEww7kScYdiJPMOxEnmDYiTzBsBN5gmEn8gTDTuSJsi4lTRGQcVcV/ouQG3vGpzea9Y+/c7az1vDU26FuO+h3k6qEs6bpkXC3HVbQ42Ip8DHjkZ3IEww7kScYdiJPMOxEnmDYiTzBsBN5gmEn8gTH2b/kJB4365rJmPXYInuvzp23TbbbD7lricHFZtuqoZxZT7zUbtZDjaUHjeEH3K8Q+zgapm9SZcTWeDh5ZCfyBMNO5AmGncgTDDuRJxh2Ik8w7ESeYNiJPMFx9i85c0wWwePs+78z1azfeMn/mvU3e85w1j6qmW221TqzjKpvX2LWz/7Pg85apmOffeUBc8aD7rcg8WnT3MVs1myb7e93F41uhwq7iHQAGACQBZBR1ZYw10dEpVOMI/u3VPVIEa6HiEqIr9mJPBE27ArgJRF5R0RWj/cDIrJaRNpFpD2N4ZA3R0SFCvs0fqmqHhKRWQDWi8j/qeqGsT+gqq0AWgGgQRrDrW5IRAULdWRX1UP5z90AngVgT2MiosgUHHYRqReR5CdfA7gKwLZidYyIiivM0/gmAM/K6LzfKgBPqeqLRekVFU0ulQrVfuSC42b9e1PsOeW1sbSz9nrMnq9+8JVms579K7tvHz2YdNZy715qtp2+zR7rbni306wfuWyuWe/5uvsVbVPAcvrTXv7QWZNed6QLDruq7gFwfqHtiai8OPRG5AmGncgTDDuRJxh2Ik8w7ESeEA25Ze/n0SCNukSWle32vGEtexzw+B7//sVm/eqfvmbWF9QeMusDuVpnbUTDncD5yK5vmvXBPVOctdhIwJbJAeVsk70UtKbt4+i0ze7fvW5ll9lWHp3prL3X9jCO9+4ft/c8shN5gmEn8gTDTuQJhp3IEww7kScYdiJPMOxEnuA4eyUI2B44lIDH99x37P/3351mT2ENEjfWNh7UarPtsWx9qNvuybinuKYDxvgf221PgT1ujOEDQCxjP6ZXfutdZ+3axk1m2/vPPM9Z26ht6NdejrMT+YxhJ/IEw07kCYadyBMMO5EnGHYiTzDsRJ7gls2VoIznOpxs9/FZZv1ow2Szfjhjb+k8Pe5e7jkZGzLbzkvY+4X2ZN3j6AAQT7iXqh7RuNn2X772O7OeWpAw6wmxl6K+1FgH4Lodf2u2rcces+7CIzuRJxh2Ik8w7ESeYNiJPMGwE3mCYSfyBMNO5AmOs3tuZo297XGtuLdcBoBqyZj1Q+lpztruoa+abd/vt88BWN603aynjbF0a549EDxOfkriY7OeUnsc3rpXlzbZ4+hbzKpb4JFdRNaISLeIbBtzWaOIrBeR3fnP7keUiCrCRJ7GPwFg+UmX3Q2gTVXnA2jLf09EFSww7Kq6AUDvSRevBLA2//VaANcUuV9EVGSFvkHXpKqdAJD/7HxxJSKrRaRdRNrTGC7w5ogorJK/G6+qraraoqotCdSU+uaIyKHQsHeJyBwAyH/uLl6XiKgUCg378wBuzn99M4DnitMdIiqVwHF2EXkawOUAZojIAQA/A3AfgF+LyK0A9gG4rpSd/NILWDde4vbca824x7rj0+xR0W9O3WrWe7INZv1YdpJZnxo/4awNZNx7twNA75B93efUdJr1zSfmOWszq+1xcqvfANAxMsOsz685bNbv73Lvn9Bce/L74Z+WWXaZs6Yb/+CsBYZdVW9wlLjbA9EXCE+XJfIEw07kCYadyBMMO5EnGHYiT3CKayUIWEpaquyHyRp623/rArPtFZPsJZPfSs016zOrBsy6Nc10Tk2f2TbZlDLrQcN+jVXu6bsD2Tqz7aSYfWp30O99YbW9DPaPX77QWUuee9Rs25AwjtHGKC6P7ESeYNiJPMGwE3mCYSfyBMNO5AmGncgTDDuRJzjOXgEkUW3Wcyl7vNkyY+uIWT+StZc8nhqzp3pWByy5bG2NfGnjXrNtT8BY+Oah0816Mu7eEnpmzB4nb07YY91bU81mfd3gWWb91r9+2Vl7uvVKs231i285a6Lux4tHdiJPMOxEnmDYiTzBsBN5gmEn8gTDTuQJhp3IE1+scXZjyWWpsseLJR7wfy1m13MpY35zzh5rDqJpeyw8jIf/6xGzvj8z1awfTtv1oCWXs8YE67eHpphta2P2dtEzq/rNen/OHqe3DOTsZa6tefpAcN/vmr7bWXum79tm20LxyE7kCYadyBMMO5EnGHYiTzDsRJ5g2Ik8wbATeaKixtnDrI8eNFat9rBnpIZWLjbr+6+xx/FvvOCPztrhTNJs+66xrTEATDHmhANAfcD66il1n/9waMTeTjporNpaFx4AZhnj8Fm1j3MH03bfggSdf3AgY6xp/zf2XPupTxbUpeAju4isEZFuEdk25rJ7ReSgiGzJf6wo7OaJqFwm8jT+CQDLx7n8IVVdlP9YV9xuEVGxBYZdVTcA6C1DX4iohMK8QXeHiLyXf5rvfIEjIqtFpF1E2tOwX98RUekUGvafAzgTwCIAnQAecP2gqraqaouqtiRQU+DNEVFYBYVdVbtUNauqOQCPArDfTiaiyBUUdhGZM+bbVQC2uX6WiCpD4Di7iDwN4HIAM0TkAICfAbhcRBYBUAAdAG4rRmescfSwqubMNuvp05vMeu8C917gJ2Ybm2IDWLRip1m/pem/zXpPtsGsJ8TYnz093Wx7waQOs/5K30KzfqRqslm3xukvrXfP6QaAYzl7//VTqj4263d98D1nrWmSPZb92Gn2AFNac2Z9V9p+ydqXc8+H/8eFr5ptn8VMs+4SGHZVvWGcix8v6NaIKDI8XZbIEww7kScYdiJPMOxEnmDYiTxRUVNch6++yKzP+skeZ21RwwGz7cK6N8x6KmcvRW1Nt9wxNNdseyJnb8m8e8QeFuzL2ENQcXEPA3WP2FNcH9hrL1vctvgXZv2nh8abI/UXsTp11o5m7WG7ayfbS0UD9mN221c2OGtnVHebbV8YnGPWDwVMgW1K9Jn1eYkeZ+27yffNtoUOvfHITuQJhp3IEww7kScYdiJPMOxEnmDYiTzBsBN5orzj7GIvF73kXzeZzZcltztrJ9SeUhg0jh40bmqZUmUvGzyctu/m7rQ9hTXI2TWHnbVVDVvMthseWWLWv5H6gVn/8Ap7em7bkHsqZ0/G/r2v33uFWd+8r9msXzxvr7N2XvKg2Tbo3IZkPGXWrWnHADCYc/+9vp2yzz8oFI/sRJ5g2Ik8wbATeYJhJ/IEw07kCYadyBMMO5EnRNU937jY6mY365k3/ZOz3nr7v5vtn+q92FlrrrW3ozut+ohZnx63t/+1JGP2mOtXE/aY6wuDp5r1146dY9a/nuxw1hJib/d8+aQPzPotP77TrGdq7WW0++e5jyeZevtvr+H8o2b9B2e9Ytarjd/9WNYeRw+634K2ZA5irUGQjNnbZD+wYpWz9oeOJ9A31Dnug8IjO5EnGHYiTzDsRJ5g2Ik8wbATeYJhJ/IEw07kibLOZ4+lgUld7vHFF/oXme3PqHOvtX0kba+P/vvj55n1U+vs7X+trYfPMuaTA8CW1FSz/mLP18z6KXX2+uld6SnO2tF0vdn2hDGvGgAef+hBs/5Al73u/KrGzc7a+dX2OPqxnH0s2hGw3v5ArtZZS6m9vkFfwDh80vh7AIC02tGKG1s+T43ZY/j957m34c52uW838MguIs0i8qqI7BSR7SLyw/zljSKyXkR25z8XvvoDEZXcRJ7GZwDcqaoLAFwM4HYRWQjgbgBtqjofQFv+eyKqUIFhV9VOVd2c/3oAwE4AcwGsBLA2/2NrAVxTqk4SUXif6w06EZkH4AIAGwE0qWonMPoPAcAsR5vVItIuIu2Z4cFwvSWigk047CIyGcBvAfxIVYN23PszVW1V1RZVbamqsd8sIqLSmVDYRSSB0aD/UlWfyV/cJSJz8vU5AOxtMYkoUoFDbyIiAB4HsFNVx47DPA/gZgD35T8/F3Rd8ZEckvuHnfWc2tMlXzninurZVDtgtl2U3G/Wd52wh3G2Dp3irG2u+orZti7u3u4ZAKZU21Nk66vc9xkAzEi4f/fTa+z/wdY0UADYlLJ/t7+f+ZpZ35dxD9L8bvBss+2OE+77HACmBSzhvbXf3f5Ext5GezhrRyOVsYdyp9TYj+lFjR85a7tgbxfdc74xbfhNd7uJjLMvBXATgK0i8ski5PdgNOS/FpFbAewDcN0ErouIIhIYdlV9A4DrkLusuN0holLh6bJEnmDYiTzBsBN5gmEn8gTDTuSJ8m7ZfHwIsdffdZZ/89JSs/k/r/yNs/Z6wHLLLxy2x0X7R+ypnjMnuU/1bTDGuQGgMWGfJhy05XNtwPa/H2fcZyYOx+ypnFnnQMuow8Pu6bMA8GZuvllP59xbNg8bNSD4/ITekRlm/ZS6PmdtIOOe/goAHQONZv1In72tcmqSHa03smc6a8tnu7cmB4C6bvdjFjP+VHhkJ/IEw07kCYadyBMMO5EnGHYiTzDsRJ5g2Ik8UdYtmxukUZdI4RPl+m50b9l8xj/sMtsunrrXrG/ut+dt7zPGXdMBSx4nYu5lgwFgUmLErNcGjDdXx91z0mOwH99cwDh7fdzuW9Bc+4Yq97zuZNye8x0ztjWeiLjxu/+xb16o604G/N4Ztf8mLpnyobO2Zu+lZtspK9zbbG/UNvRrL7dsJvIZw07kCYadyBMMO5EnGHYiTzDsRJ5g2Ik8Uf5x9vhV7h/I2WuYhzF47RKzvuSeTXY96R4XPae6y2ybgD1eXBswnlwfs8fCU8ZjGPTf/I2hZrOeDbiGVz5eYNbTxnhz14kGs23COH9gIqx9CIYyAVs2D9nz3eMxOzep1+y59tN3uM+dqFln/y1aOM5ORAw7kS8YdiJPMOxEnmDYiTzBsBN5gmEn8kTgOLuINAN4EsBsADkArar6sIjcC+DvAPTkf/QeVV1nXVfY+eyVSi6y16Qfml1n1muO2nOjB06z2zd86F6XPjZsrzmf+9NOs05fLNY4+0Q2icgAuFNVN4tIEsA7IrI+X3tIVf+tWB0lotKZyP7snQA6818PiMhOAHNL3TEiKq7P9ZpdROYBuADAxvxFd4jIeyKyRkSmOdqsFpF2EWlPw366SkSlM+Gwi8hkAL8F8CNV7QfwcwBnAliE0SP/A+O1U9VWVW1R1ZYE7P3UiKh0JhR2EUlgNOi/VNVnAEBVu1Q1q6o5AI8CWFy6bhJRWIFhFxEB8DiAnar64JjL54z5sVUAthW/e0RULBN5N34pgJsAbBWRLfnL7gFwg4gsAqAAOgDcVpIefgHopq1m3Z4sGazhrcLbhluMmb5MJvJu/BvAuIuLm2PqRFRZeAYdkScYdiJPMOxEnmDYiTzBsBN5gmEn8gTDTuQJhp3IEww7kScYdiJPMOxEnmDYiTzBsBN5gmEn8kRZt2wWkR4AH425aAaAI2XrwOdTqX2r1H4B7Fuhitm301R15niFsob9Mzcu0q6qLZF1wFCpfavUfgHsW6HK1Tc+jSfyBMNO5Imow94a8e1bKrVvldovgH0rVFn6FulrdiIqn6iP7ERUJgw7kSciCbuILBeRXSLygYjcHUUfXESkQ0S2isgWEWmPuC9rRKRbRLaNuaxRRNaLyO7853H32Iuob/eKyMH8fbdFRFZE1LdmEXlVRHaKyHYR+WH+8kjvO6NfZbnfyv6aXUTiAN4HcCWAAwA2AbhBVXeUtSMOItIBoEVVIz8BQ0QuA3AcwJOqem7+svsB9Krqffl/lNNU9a4K6du9AI5HvY13freiOWO3GQdwDYBbEOF9Z/Tr+yjD/RbFkX0xgA9UdY+qjgD4FYCVEfSj4qnqBgC9J128EsDa/NdrMfrHUnaOvlUEVe1U1c35rwcAfLLNeKT3ndGvsogi7HMB7B/z/QFU1n7vCuAlEXlHRFZH3ZlxNKlqJzD6xwNgVsT9OVngNt7ldNI24xVz3xWy/XlYUYR9vK2kKmn8b6mqXgjgagC355+u0sRMaBvvchlnm/GKUOj252FFEfYDAJrHfH8qgEMR9GNcqnoo/7kbwLOovK2ouz7ZQTf/uTvi/vxZJW3jPd4246iA+y7K7c+jCPsmAPNF5HQRqQZwPYDnI+jHZ4hIff6NE4hIPYCrUHlbUT8P4Ob81zcDeC7CvnxKpWzj7dpmHBHfd5Fvf66qZf8AsAKj78h/COAnUfTB0a8zAPwp/7E96r4BeBqjT+vSGH1GdCuA6QDaAOzOf26soL79D4CtAN7DaLDmRNS3b2D0peF7ALbkP1ZEfd8Z/SrL/cbTZYk8wTPoiDzBsBN5gmEn8gTDTuQJhp3IEww7kScYdiJP/D866iIlQ3gtyAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(training_images[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#print(training_labels[0])\n",
    "print(training_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normailicemos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images  = training_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definamos la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential: Define la secuencia de capas\n",
    "\n",
    "Flatten: transforma la matriz en un vector.\n",
    "\n",
    "Dense: define el numero de neuronas de la capa\n",
    "\n",
    "Cada capa requiere una función de activación\n",
    "\n",
    "Relu  \"If X>0 return X, else return 0\" -- solo pasa valores positivos \n",
    "\n",
    "Softmax devuelve el mayor dentro de un vector "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "entrenemos la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.5038 - accuracy: 0.8248\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.3795 - accuracy: 0.8639\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.3395 - accuracy: 0.8757\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3133 - accuracy: 0.8856\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.2989 - accuracy: 0.8900\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.2823 - accuracy: 0.8960\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.2691 - accuracy: 0.8991\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.2589 - accuracy: 0.9033\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.2499 - accuracy: 0.9064\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.2416 - accuracy: 0.9101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18fffcf7c48>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluemos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 90us/sample - loss: 0.3436 - accuracy: 0.8797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34359648132324216, 0.8797]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.10002666e-07 1.65904387e-10 2.05897788e-08 1.94076333e-09\n",
      " 1.09246265e-07 1.44949983e-04 7.89687874e-07 1.74722553e-03\n",
      " 2.03908229e-07 9.98105884e-01]\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que sucede si cambiamos el numero de neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n",
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1868\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.0731\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0479\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.0350\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.0265\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.0212\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.0167\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.0156\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.0139\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.0126\n",
      "10000/10000 [==============================] - 1s 71us/sample - loss: 0.1067\n",
      "[5.3330455e-17 8.4339362e-14 3.5897426e-14 9.9458424e-09 1.3122073e-20\n",
      " 1.5060935e-15 2.1658048e-24 1.0000000e+00 2.7716189e-16 9.4934199e-15]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=10)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " si quitamos el flattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: nan\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: nan\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: nan\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: nan\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: nan\n",
      "10000/10000 [==============================] - 1s 66us/sample - loss: nan\n",
      "[nan nan nan nan nan]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(5, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideremos el efecto de de una capa adicional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1875\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.0809\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.0565\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.0424\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.0338\n",
      "10000/10000 [==============================] - 1s 60us/sample - loss: 0.0987\n",
      "[2.2900770e-13 2.2825318e-10 1.4168861e-10 1.3145402e-11 1.7155001e-12\n",
      " 3.0417367e-11 7.0707134e-18 9.9999976e-01 6.0766075e-12 2.8122292e-07]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siempre tenemos que definie las iteraciones y esperar hasta el final?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.4756 - accuracy: 0.8286\n",
      "Reached 60% accuracy so cancelling training!\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.4754 - accuracy: 0.8286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x190028bff48>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('accuracy')>0.6):\n",
    "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
